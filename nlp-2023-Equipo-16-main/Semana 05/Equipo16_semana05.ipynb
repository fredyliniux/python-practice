{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"data/itesm.png\"/></center>\n",
    "<h1 style='text-align: center;'><b>Maestría en Inteligencia Artificial Aplicada</b></h1>\n",
    "\n",
    "<h2 style='text-align: center;'><b>Curso: Estrategia de implementación de servicios tecnológicos</b></h2>\n",
    "<h2 style='text-align: center;'><b>Tecnológico de Monterrey</b></h2>\n",
    "<h2 style='text-align: center;'><b>Prof Titular: Luis Eduardo Falcón Morales</b></h2>\n",
    "<h2 style='text-align: center;'><b>Prof Tutor: Carlos Villaseñor</b></h2>\n",
    "\n",
    "<h3 style='text-align: center;'><b>ALUMNO: </b>Cecilia Acevedo Rodríguez</h3>\n",
    "<h3 style='text-align: center;'><b>MATRICULA: </b>A01793953</h3>\n",
    "<h3 style='text-align: center;'><b>ALUMNO: </b>Johan Andrés Castro Gomez</h3>\n",
    "<h3 style='text-align: center;'><b>MATRICULA: </b>A01793556</h3>\n",
    "<h3 style='text-align: center;'><b>ALUMNO: </b> Guillermo Alfonso Muñiz Hermosillo</h3>\n",
    "<h3 style='text-align: center;'><b>MATRICULA: </b>A01793101</h3>\n",
    "<h3 style='text-align: center;'><b>ALUMNO: </b>Ricardo Morales Bustillos</h3>\n",
    "<h3 style='text-align: center;'><b>MATRICULA: </b>A01740032</h3>\n",
    "<h3 style='text-align: center;'><b>ALUMNO: </b>Fredy Reyes Sánchez</h3>\n",
    "<h3 style='text-align: center;'><b>MATRICULA: </b>A01687370</h3>\n",
    "\n",
    "\n",
    "\n",
    "<h2 style='text-align: center;'><b>Actividad de la Semana 05</b></h2>\n",
    "<h2 style='text-align: center;'><b>5.2 Actividad: Continuando con caso de estudio: Amazon-Yelp-Imdb</b></h1>\n",
    "<h4 style='text-align: right;'>Mayo 2023</h4>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ejercicio - 1:**\n",
    "\n",
    "Descarga los 3 archivos de Canvas. En particular, el archivo de datos de IMDb ya no requiere\n",
    "transformarse para obtener sus 1000 registros. Al cargar los datos de los tres archivos deberás\n",
    "tener un DataFrame de Pandas de 3000 registros, con sus etiquetas. Los archivos los encuentras en\n",
    "Canvas y se llaman: amazon5.txt, imdb5.txt, yelp5.txt. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   review  3000 non-null   object\n",
      " 1   label   3000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 47.0+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gmuni\\AppData\\Local\\Temp\\ipykernel_25132\\717470586.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  pd.read_csv('data/imdb5.txt', sep='   ', names=['review','label'], header=None, encoding='utf-8'),\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "\n",
    "df = pd.concat([pd.read_csv('data/amazon5.txt', sep='\\t', names=['review','label'], header=None, encoding='utf-8'), \n",
    "                pd.read_csv('data/imdb5.txt', sep='   ', names=['review','label'], header=None, encoding='utf-8'), \n",
    "                pd.read_csv('data/yelp5.txt', sep='\\t', names=['review','label'], header=None, encoding='utf-8')], \n",
    "               ignore_index=True) \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review    0\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ejercicio - 2:**\n",
    "\n",
    "Realiza de nuevo un proceso de limpieza. Aplica el preprocesamiento que consideres adecuado, sin\n",
    "embargo, deberás aplicar necesariamente alguna de las técnicas de lematización. Como aplicaremos\n",
    "modelos embebidos pre-entrenados, queremos palabras lo más cercanas a las existentes en un\n",
    "idioma, inglés en este caso. Aplica y justifica cualquier otro proceso de limpieza que consideres\n",
    "adecuado. Recuerda que en esta actividad se usarán vectores embebidos para un problema de\n",
    "clasificación, por lo que deberás tomar de acuerdo a este contexto. Justifica todas las\n",
    "transformaciones que se apliquen. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gmuni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\gmuni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\gmuni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\gmuni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gmuni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos las librerias necesarias.\n",
    "import re\n",
    "import nltk\n",
    "# Importamos la libreria de lemanizacion de nltk para aplicarla a nuestro documento.\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Necesitamos crear un conjunto de stopwords. Usamos el conjunto predefinido en la practica anterior de la libreria nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')    # para tener acceso a \"stopwords\" en varios idiomas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# Asi mismo usaremos el conjunto de las palabras negativas usadas en la practica anterior.\n",
    "negwords = [ 'no', 'nor', 'not', 'ain', 'aren', \"aren't\", 'don', \"don't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "# Definimos nuestro conjunto de stopwords customizado, \n",
    "# quitando las palabras negativas del conjunto de nltk para considerarlas al momento de realizar nuestro analisis de sentimiento.\n",
    "mystopwords = [w for w in stopwords.words('english') if w not in negwords ]\n",
    "\n",
    "\n",
    "def tag_word(tag):\n",
    "    if tag == 'VERB':\n",
    "        return 'v'\n",
    "    if tag == 'ADV':\n",
    "        return 'r'\n",
    "    if tag == 'ADJ':\n",
    "        return 'a'\n",
    "    else:\n",
    "        return 'n'\n",
    "\n",
    "\n",
    "# Antes de comenzar separamos nuestros documentos y nuestras labels en 2 conjuntos de datos denominados X y Y\n",
    "X = df.review     # Serie de strings\n",
    "Y = df.label      # Serie de enteros 0s y 1s\n",
    "\n",
    "# Una vez separados comenzamos el procesamiento de nuestras strings.  \n",
    "# Creamos una funcion para llevar a cabo este proceso paso por paso.\n",
    "def clean_doc(doc):\n",
    "    #Remplazamos todos los caracteres que no sean alfabéticos por espacio\n",
    "    newDoc = re.sub(r'[^A-Za-z\\s]',' ', doc) \n",
    "    # Convertir a minusculas nuestro documento. Ya que facilita el analisis de cada documento y las transformaciones a realizar.\n",
    "    newDoc = doc.lower()\n",
    "     # Eliminar toda la puntuacion (excepto salto de lineas y puntos ya que son tratados en el siguiente paso) ya que no son relevantes para nuestro analisis.\\n\",\n",
    "    newDoc = re.sub(r'[^a-z|^\\\\n|^ |^\\\\.]+', ' ', newDoc)\n",
    "    # Eliminar puntos finales, seguidos y suspensivos.\n",
    "    newDoc = re.sub(r'(\\\\.+)', ' ', newDoc)\n",
    "    # Eliminar espacios multiples.\n",
    "    newDoc = re.sub(r'\\s+', ' ',newDoc).strip() #Quitamos todos los espacios adicionales\n",
    "    tokens = word_tokenize(newDoc)\n",
    "    # Lemmatization\n",
    "    word_type = pos_tag(tokens, tagset='universal')\n",
    "    tokens = [wnl.lemmatize(x[0],pos = tag_word(x[1]))for x in word_type]\n",
    "    # Eliminar stopwords, Eliminamos tambien palabras de longitud 1\n",
    "    tokens = [word for word in tokens if (word not in mystopwords) & (len(word)>=2)]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño final del conjunto de datos: 3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['no', 'way', 'plug', 'unless', 'go', 'converter'],\n",
       " ['good', 'case', 'excellent', 'value'],\n",
       " ['great', 'jawbone'],\n",
       " ['tie', 'charger', 'conversation', 'last', 'minutes.major', 'problem'],\n",
       " ['mic', 'great']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Procesamos cada doc en el corpus\n",
    "Xclean = [clean_doc(x) for x in X]  \n",
    "print(f\"Tamaño final del conjunto de datos: {len(Xclean)}\")\n",
    "Xclean[0:5] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3. \n",
    "Llamar Xclean a los comentarios procesados y Y a las etiquetas. Realicemos una partición aleatoria\n",
    "con los mismos porcentajes de la práctica pasada para poder comparar dichos resultados con los de\n",
    "esta actividad, a saber, 70%, 15% y 15%, para entrenamiento, validación y prueba,\n",
    "respectivamente. Verifica que obtienes 2100 registros de entrenamiento y 450 para cada uno de\n",
    "validación y prueba. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X,y Train: 2100 2100\n",
      "X,y Val: 450 450\n",
      "X,y Test 450 450\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val_test, y_train, y_val_test = train_test_split(Xclean, Y, train_size=.70, shuffle=True, random_state=1) \n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val_test, y_val_test, test_size=.50, shuffle=True, random_state=17)\n",
    "\n",
    "print('X,y Train:', len(x_train), len(y_train))\n",
    "print('X,y Val:', len(x_val), len(y_val))\n",
    "print('X,y Test', len(x_test), len(y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 4. \n",
    "Usando el conjunto de entrenamiento genera un vocabulario que no sea mayor a 1500 palabras, ni\n",
    "menor a 1000. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del diccionario antes de la limpieza:  3398\n",
      "Tamaño del vocabulario Filtrado: 1451\n",
      "Palabras mas frecuentes:\n",
      "(palabra,frecuencia):\n",
      "[('not', 225), ('good', 192), ('great', 141), ('movie', 140), ('phone', 132), ('film', 130), ('work', 113), ('bad', 106), ('time', 101), ('like', 100)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "midiccionario = Counter()    \n",
    "\n",
    "for k in range(len(x_train)):\n",
    "  midiccionario.update(x_train[k])\n",
    "print('Tamaño del diccionario antes de la limpieza: ', len(midiccionario))\n",
    "\n",
    "min_freq = 2\n",
    "\n",
    "midiccionario = Counter((({tk: count for tk,count in midiccionario.items() if count >= min_freq})))\n",
    "\n",
    "print('Tamaño del vocabulario Filtrado:', len(midiccionario))  \n",
    "print('Palabras mas frecuentes:\\n(palabra,frecuencia):') \n",
    "print(midiccionario.most_common(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Por qué es importante acotar un vocabulario inferior y superiormente? \n",
    "\n",
    "R: Es importante para reducir la complejidad de nuestro corpus, ayudando a simplificar el procesamiento y hacerlo mas eficiente y reduciendo el uso de recursos computacionales. Tambien nos puede ayudar en la comprension del contexto de los documentos que estemos procesando ya que el modelo puede aprender con mayor precision las asociaciones y relaciones que pueden existir entre ellas. Asi mismo mejora el rendimiento y velocidad de respuesta de los modelos, haciendolo especialmente importante para aplicaciones donde es necesario procesar el texto rapidamente.\n",
    "\n",
    "- ¿Por qué debe usarse solamente el conjunto de entrenamiento para generar el diccionario? \n",
    "\n",
    "R: El conjunto de entrenamiento es comunmente el conjunto mas representativo de nuestro corpus linguistico. Al utilizar este conjunto se asegura el uso de las palabras mas relevantes y frecuentes reflejando mejor el lenguaje y el domininion del problema. Se evita la filtracion de datos y se le da mas coherencia a la representacion del texto ya que se puede mapear correctamente el diccionario a nuestro corpus. \n",
    "\n",
    "Con este vocabulario que obtienes, filtra los conjuntos de entrenamiento, validación y prueba, de esta\n",
    "manera todos los comentarios usarán solamente palabras válidas de acuerdo a este vocabulario.\n",
    "Indica el tamaño del vocabulario obtenido. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_data(x_data):\n",
    "    filtered_data = []\n",
    "    for doc in x_data:\n",
    "        filtered_data.append([w for w in doc if w in midiccionario])\n",
    "    return filtered_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del conjunto de entrenamiento Filtrado: 2100\n",
      "Longitud del conjunto de validacion Filtrado: 450\n",
      "Longitud del conjunto de Pureba Filtrado: 450\n"
     ]
    }
   ],
   "source": [
    "filtered_train_x = get_filtered_data(x_train)\n",
    "print('Longitud del conjunto de entrenamiento Filtrado:', len(filtered_train_x))  \n",
    "\n",
    "\n",
    "filter_val_x = get_filtered_data(x_val)\n",
    "print('Longitud del conjunto de validacion Filtrado:', len(filter_val_x))  \n",
    "\n",
    "filtered_test_x = get_filtered_data(x_test)\n",
    "print('Longitud del conjunto de Pureba Filtrado:', len(filtered_test_x))  \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 5\n",
    "\n",
    "Utilizarás los vectores embebidos FastText preentrenados por Facebook.\n",
    "* a. Incluye una tabla comparativa de pros y contras entre los modelos FastText, word2vec de\n",
    "Google y Glove de Stanford. Puedes consultar sus páginas correspondientes:\n",
    "\n",
    "    - https://fasttext.cc/\n",
    "    - https://code.google.com/archive/p/word2vec/\n",
    "    - https://nlp.stanford.edu/projects/glove/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "\n",
    "# fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "ft = fasttext.load_model('data/cc.en.300.bin')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  |    FastText    | word2vec de Google  |   GloVe de Stanford    |\n",
    "| --- | --- | --- | --- |\n",
    "| Pros  |   Considera la estructura de subpalabras, lo que permite capturar la información de las palabras compuestas y las relaciones morfológicas más finas.  |    Proporciona un rendimiento y calidad de vectores que son adecuados para tareas de procesamiento del lenguaje natural. |    Considera la coocurrencia global de palabras en un corpus, lo que ayuda a capturar relaciones semánticas más amplias |\n",
    "|   |   Buen rendimiento en tareas de análisis de sentimientos  |    Conserva relaciones semánticas y sintácticas |    Extensamente pre-entrenado en una amplia variedad de corpus, lo que le brinda una base sólida para diferentes tareas de NLP. |\n",
    "|   |   Manejo de palabras fuera del vocabulario, lo que permite generar vectores para palabras raras o poco frecuentes.  |    Modelos pre-entrenados en múltiples idiomas,  lo que facilita su aplicación en diferentes entornos lingüísticos. |    Mantiene relaciones semánticas lineales, lo que permite operaciones de analogía como \"rey - hombre + mujer = reina\". |\n",
    "|   |   Adecuado para lenguajes con palabras compuestas o morfología compleja  |    Capacidad para manejar grandes volúmenes de texto |    Capacidad para generar vectores de palabras extrañas |\n",
    "|   |   |    Modelos pre-entrenados disponibles en diversos tamaños |  |\n",
    "| Contras  |   Mayor complejidad computacional, especialmente durante el entrenamiento debido a la consideración de subpalabras.  |    Requiere grandes conjuntos de datos para entrenamiento para obtener vectores de alta calidad y generalizables. |    Requiere grandes conjuntos de datos para entrenamiento |\n",
    "|   |   Tiempo de entrenamiento más largo en comparación con otros modelos, debido a la complejidad computacional y la consideración de subpalabras.  |    Dependencia de la disponibilidad de datos de Google ya que depende de la recopilacion de datos de Google |    Los vectores pueden ser sensibles al ruido del corpus |\n",
    "|   |   Requiere un mayor almacenamiento de datos ya que la consideración de subpalabras aumenta  | |  |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 6\n",
    "\n",
    "Utiliza el modelo FastText de vectores embebidos pre-entrenados de dimensión 300 para generar\n",
    "un nuevo diccionario clave-valor, donde la “clave” será cada token o palabra de tu vocabulario y el\n",
    "“valor” será su vector embebido de dimensión 300. Este diccionario deberá ser del mismo tamaño\n",
    "que el vocabulario previo que hayas construido previamente.\n",
    "\n",
    "- https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "\n",
    "NOTA: Debido a la cantidad de recursos computacionales que demanda cargar los vectores\n",
    "FastText (son 2 millones de vectores), es recomendable que una vez que generes el nuevo\n",
    "vocabulario de vectores embebidos, guardes dicho diccionario en un archivo (pickle, npz o el que\n",
    "consideres más adecuado). Una vez realizado lo anterior, puedes borrar la variable de FastText\n",
    "para liberar memoria RAM. De esta manera, ya tienes tu vocabulario de vectores embebidos de\n",
    "acuerdo a los tokens que consideras más adecuados para tu problema y puedes usarlo rápidamente\n",
    "cuando lo necesites. En dado caso apóyense entre los miembros del equipo de tener dificultades\n",
    "para generar el vocabulario y por mientras puedes usar el archivo del vocabulario que alguno haya\n",
    "generado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "with open('data/vect_Vocabulario.pkl', 'wb') as file:\n",
    "    pickle.dump(dict(zip(midiccionario.keys(), np.array([ft.get_word_vector(word) for word in midiccionario]))), file)\n",
    "\n",
    "del ft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de vocabulario: 1451\n",
      "Tamaño de vocabulario de vectores: 1451\n"
     ]
    }
   ],
   "source": [
    "with open('data/vect_Vocabulario.pkl', 'rb') as file:\n",
    "    vect_vocabulario = pickle.load(file)\n",
    "print(f\"Tamaño de vocabulario: {len(midiccionario)}\")\n",
    "print(f\"Tamaño de vocabulario de vectores: {len(vect_vocabulario.keys())}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 7\n",
    "\n",
    "Una manera de utilizar los vectores embebidos con modelos de aprendizaje automático en\n",
    "documentos de texto, es asignar a cada comentario filtrado el vector embebido de dimensión 300\n",
    "que resulta de promediar todos sus tokens. Así, en este ejercicio deberás generar los arreglos\n",
    "correspondientes para los conjuntos de entrenamiento, validación y prueba. Los llamaremos\n",
    "trainEmb, valEmb y testEmb, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_promedioFromDoc(doc):\n",
    "    if len(doc) > 0:\n",
    "        promedio = np.mean([vect_vocabulario[word] for word in doc if word in vect_vocabulario], axis=0).reshape(-1,1)\n",
    "    else:\n",
    "        promedio = np.random.uniform(-1,1,(300,1)).astype(np.float32)\n",
    "    return promedio\n",
    "\n",
    "def get_emb(x_data):\n",
    "    cbb = np.array(get_promedioFromDoc(x_data[0]))\n",
    "    for doc in x_data[1:]:\n",
    "        cbb = np.append(cbb, get_promedioFromDoc(doc), axis=1)\n",
    "\n",
    "    cbb = cbb.T\n",
    "    return cbb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del vector embebido de entrenamiento : (2100, 300)\n",
      "Forma del vector embebido de validacion : (450, 300)\n",
      "Forma del vector embebido de pruebas : (450, 300)\n"
     ]
    }
   ],
   "source": [
    "trainEmb = get_emb(filtered_train_x)\n",
    "\n",
    "valEmb = get_emb(filter_val_x)\n",
    "\n",
    "testEmb = get_emb(filtered_test_x)\n",
    "\n",
    "print('Forma del vector embebido de entrenamiento :', trainEmb.shape)  \n",
    "print('Forma del vector embebido de validacion :', valEmb.shape)  \n",
    "print('Forma del vector embebido de pruebas :', testEmb.shape) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Cuáles son sus dimensiones? \n",
    "\n",
    "R: Las dimension de los vectoreas es de la misma longitud que nuestros conjuntos, para entrenammiento (2100), para validación (450) y para pruebas (450), cada uno contará con 300 valores que corresponden al promedio de los valores de sus vectores embebidos por cada token en ellos.\n",
    "\n",
    "- ¿Se podrían usar para su representación matrices dispersas (sparse matrices) como en el caso de la matriz Tf-idf?\n",
    "\n",
    "R: Las matrices dispersas son matrices que contienen principalmente valores 0 y se utilizan para almacenar datos escasos o con alta dimensionalidad, en el caso de estas matrices generadas la mayorita cuenta con valores no ceros. Es decir que hablariamos de matrices densas con las cuales tambien podemos generar matrices tf-idf solo que estas tienen un mayor costo en memoria y procesamiento que una matriz dispersa.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 8\n",
    "\n",
    "Utiliza los modelos de regresión lineal y bosque aleatorio (random forest) y encuentra sus\n",
    "desempeños (accuracy). Compara los resultados con los de la semana anterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: Train-accuracy: 84.67%\n",
      "LR: Val-accuracy: 83%\n",
      "\n",
      "RF: Train-accuracy: 76.76%\n",
      "RF: Val-accuracy: 73.33%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "modeloLRcount = LogisticRegression(max_iter=1000, solver=\"sag\", random_state=42)\n",
    "modeloLRcount.fit(trainEmb, y_train)\n",
    "\n",
    "modeloRFcount = RandomForestClassifier(ccp_alpha=0.001, n_estimators=3, max_features= 'sqrt', max_depth= 4, min_samples_leaf= 5,random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "modeloRFcount.fit(trainEmb, y_train)\n",
    "\n",
    "print('LR: Train-accuracy: %.2f%%' % (100*modeloLRcount.score(trainEmb, y_train)))\n",
    "print('LR: Val-accuracy: %2.f%%' % (100*modeloLRcount.score(valEmb, y_val)))\n",
    "\n",
    "print('\\nRF: Train-accuracy: %.2f%%' % (100*modeloRFcount.score(trainEmb, y_train)))\n",
    "print('RF: Val-accuracy: %.2f%%' % (100*modeloRFcount.score(valEmb, y_val)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En comparacion a la tarea anterior, el modelo de regresion logistica notamos un mejor rendimiento no asi el Random Forest que se mantuvo similar a los valores anteriores. Creemos que esto podria deberse la limpieza o lemmatizacion de los datos. Quiza seria necesario refinar un poco estos si queremos que random fores nos brinde un mejor modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 9\n",
    "\n",
    "Obtener la matriz de confusión e interpretar sus valores. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Una vez entrenado el modelo, podemos predecir los resultados en nuestro conjuntos de pruebas mediante el metodo predict de nuestro modelo.\n",
    "y_predict = modeloLRcount.predict(testEmb)\n",
    "\n",
    "\n",
    "# Obtenidas las predicciones, es necesario crear nuestra matriz de confusion\n",
    "# con el objetivo de medir el comportamiento de nuestro modelo.\n",
    "# Utilizando el metodo correspondiente, nuestro conjunto de prueba y las predicciones realizadas\n",
    "# Obtenemos nuestra matriz. La cual podemos mostrar con un heatmap de la libreria seaborn.\n",
    "\n",
    "cm = confusion_matrix(y_test,y_predict)\n",
    "sns.heatmap(cm, annot=True, fmt = \"d\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_predict = modeloRFcount.predict(testEmb)\n",
    "cm = confusion_matrix(y_test,y_predict)\n",
    "sns.heatmap(cm, annot=True, fmt = \"d\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar como nuestro modelo de regresion logistca superó al modelo de bosque aleatorio en términos de precisión. El modelo de regresión logística alcanzó un accuracy del 83%, generando valores mas altos en la matriz de confusion para los verdaderos negativos(181/151) y los verdaderos positivos (192/164). Esto sugiere que el enfoque de regresión logística fue más efectivo para este conjunto de datos y resalta la importancia de considerar diferentes algoritmos y técnicas para obtener los mejores resultados en un problema de clasificación. \n",
    "\n",
    "Sin embargo, creemos que es necesario profundizar en el análisis, la limpieza y evaluaciones de datos para determinarlas fortalezas y debilidades de cada modelo y con ello garantizar que los resultados puedan extrapolarse a otros conjuntos de datos y escenarios. Notamos que los los valores de los falsos positivos y negativos notamos que son altos por lo que también representan una área de oportunidad. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='text-align: center;'>CONCLUSIONES FINALES</h2>\n",
    "\n",
    "Al comparar el uso de vectores embebidos y matrices TF-IDF pudimos identificar algunas ventajas y desventajas, así mismo notamos un impacto significativo en las métricas de evaluación del modelo.\n",
    "\n",
    "Consideramos que una de las ventajas de utilizar vectores embebidos radica en su capacidad para capturar relaciones semánticas y significados contextuales en los datos. Al utilizar técnicas como la fasttext y modelado de lenguaje basado en transformers, los vectores embebidos pueden capturar información rica y compleja sobre las palabras y su contexto en un texto. Esto puede ser especialmente beneficioso en tareas de procesamiento de lenguaje natural, donde el significado y la representación de las palabras son cruciales.\n",
    "\n",
    "Por otro lado, las matrices TF-IDF tienen la ventaja de ser más simples y rápidas de calcular. La matriz TF-IDF se basa en la frecuencia de términos y su importancia relativa en un conjunto de documentos. Esto puede ser útil en casos donde el enfoque principal es la frecuencia y relevancia de las palabras en un texto, como en la clasificación de documentos o en tareas de filtrado de información.\n",
    "\n",
    "Sin embargo, el uso de vectores embebidos puede tener un impacto positivo en las métricas de evaluación del modelo en comparación con las matrices TF-IDF. Los vectores embebidos, al capturar el significado y las relaciones contextuales, pueden proporcionar una representación más rica y sofisticada de los datos. Esto puede resultar en una mejor capacidad de generalización y en un rendimiento superior en métricas de evaluación como precisión, recall y F1-score.\n",
    "\n",
    "Por otro lado, una desventaja de los vectores embebidos es su mayor complejidad computacional y la necesidad de contar con grandes cantidades de datos para entrenar modelos de lenguaje. Además, los vectores embebidos pueden estar sujetos a sesgos inherentes en los datos de entrenamiento, lo que puede afectar la capacidad del modelo para generalizar a casos nuevos y diversos.\n",
    "\n",
    "En resumen, los vectores embebidos ofrecen una representación más rica y contextual de los datos, lo que puede llevar a un mejor rendimiento en las métricas de evaluación del modelo en comparación con las matrices TF-IDF. Sin embargo, también es importante considerar la complejidad computacional y las posibles limitaciones y sesgos asociados con los vectores embebidos al seleccionar la mejor técnica para un problema específico."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
